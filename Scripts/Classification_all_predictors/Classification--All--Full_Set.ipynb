{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries \n",
    "# make sure that tree_functions_2.py is in the same directory as this notebook\n",
    "\n",
    "from tree_functions_2 import *\n",
    "\n",
    "# calling the appropriate tools for classification\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import accuracy_score, matthews_corrcoef, precision_score\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change figure configurations\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "font = {'size':16}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "matplotlib.rc('figure', figsize = (5.0, 5.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the order of the trees \n",
    "\n",
    "n = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting a random seed\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the Tree List and the Associated Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the list of all non-isomorphic trees of order n\n",
    "\n",
    "Tree_List = list(nx.nonisomorphic_trees(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes for trees\n",
    "\n",
    "classes = ['path-like', 'star-like']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation-based total ordering on Tree_List\n",
    "\n",
    "total_tree_evaluation_list = get_total_list_evaluation_based(Tree_List, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifying the trees Tree_List as 'path-like' and 'star-like'\n",
    "# based on the total ordering\n",
    "\n",
    "for j in range(len(total_tree_evaluation_list)):\n",
    "    \n",
    "    if j < len(total_tree_evaluation_list)/2:\n",
    "        \n",
    "        total_tree_evaluation_list[j].append(classes[0])\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        total_tree_evaluation_list[j].append(classes[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data frame containing the following graph statistics:\n",
    "# log_{10}(P(.;2,1)), radius,  diameter, degree centrality, \n",
    "# closeness centrality, between centrality,\n",
    "# Stirling Numbers of the First Kind for Trees, number of leaves, and class \n",
    "\n",
    "df = []\n",
    "\n",
    "for i in range(len(total_tree_evaluation_list)):\n",
    "    \n",
    "    x = total_tree_evaluation_list[i]\n",
    "        \n",
    "    df.append([np.log10(float(x[0])), nx.radius(x[1]), nx.diameter(x[1]),\n",
    "               get_degree_centrality(x[1]),\n",
    "               get_closeness_centrality(x[1]),\n",
    "               get_betweenness_centrality(x[1]),\n",
    "               get_stirling_trees(x[1], n),\n",
    "               get_leaf_number(x[1]),\n",
    "              x[3]])\n",
    "    \n",
    "df = pd.DataFrame(df, columns = ['Log_Dist', 'Rad', 'Diam', 'Deg_Cent', \n",
    "                                 'Cls_Cent', 'Btw_Cent', 'Stirling', 'Leaf_Num', 'Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Splitting the Tree List to Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(np.array(list(df.loc[:, 'Stirling']))).iloc[:, 1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1 = pd.DataFrame(np.array(list(df.loc[:, 'Cls_Cent'])))\n",
    "\n",
    "X_2 = pd.DataFrame(np.array(list(df.loc[:, 'Btw_Cent'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_3 = pd.concat([X_1, X_2], axis = 1)\n",
    "\n",
    "X_3.columns = ['Cls_Cent', 'Btw_Cent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X, X_3], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.ravel(np.array(pd.DataFrame(df.loc[:, 'Class'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.5, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting a random seed\n",
    "\n",
    "random_state =  np.random.RandomState(seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree with Gini Criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree with gini\n",
    "\n",
    "dtc = DecisionTreeClassifier(random_state = random_state)\n",
    "\n",
    "# DecisionTreeClassifier(*, criterion='gini', splitter='best', \n",
    "#                       max_depth=None, min_samples_split=2, min_samples_leaf=1, \n",
    "#                       min_weight_fraction_leaf=0.0, max_features=None, \n",
    "#                       random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
    "#                       class_weight=None, ccp_alpha=0.0)\n",
    "\n",
    "dtc.fit(X_train, y_train)\n",
    "\n",
    "y_train_dtc_pred = dtc.predict(X_train)\n",
    "\n",
    "y_test_dtc_pred = dtc.predict(X_test)\n",
    "\n",
    "print('Train Score:', dtc.score(X_train, y_train))\n",
    "\n",
    "print('Test Score:', dtc.score(X_test, y_test))\n",
    "\n",
    "print('Train Matthews Corr:', matthews_corrcoef(y_train, y_train_dtc_pred))\n",
    "\n",
    "print('Test Matthews Corr:', matthews_corrcoef(y_test, y_test_dtc_pred))\n",
    "\n",
    "print('--------')\n",
    "\n",
    "print('Train Confusion Matrix:')\n",
    "\n",
    "cm_train_dtc = confusion_matrix(y_train, y_train_dtc_pred, labels = classes)\n",
    "\n",
    "fig = sns.heatmap(cm_train_dtc, annot = True, fmt = 'd', cbar = False)\n",
    "\n",
    "plt.xlabel('Pedicted')\n",
    "\n",
    "plt.ylabel('True')\n",
    "\n",
    "plt.show()\n",
    "    \n",
    "print('--------')\n",
    "\n",
    "print('Test Confusion Matrix:')\n",
    "\n",
    "cm_test_dtc = confusion_matrix(y_test, y_test_dtc_pred, labels = classes)\n",
    "\n",
    "fig = sns.heatmap(cm_test_dtc, annot = True, fmt = 'd', cbar = False)\n",
    "\n",
    "plt.xlabel('Pedicted')\n",
    "\n",
    "plt.ylabel('True')\n",
    "\n",
    "plt.show()\n",
    "    \n",
    "print('--------')\n",
    "\n",
    "print('Test Classification Report:')\n",
    "\n",
    "print(classification_report(y_test, y_test_dtc_pred))\n",
    "\n",
    "report = classification_report(y_test, y_test_dtc_pred, output_dict = True)\n",
    "\n",
    "report1 = pd.DataFrame(report).transpose()\n",
    "\n",
    "report1\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/tree.html#tree\n",
    "\n",
    "#tree_data = tree.export_graphviz(dtc, out_file = None) \n",
    "\n",
    "#graph = graphviz.Source(tree_data) \n",
    "\n",
    "#graph  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DF.append(['dtc', 'gini', 0, \n",
    "           round(dtc.score(X_train, y_train), 5), round(dtc.score(X_test, y_test), 5), \n",
    "           round(matthews_corrcoef(y_train, y_train_dtc_pred), 5), \n",
    "           round(matthews_corrcoef(y_test, y_test_dtc_pred), 5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://scikit-learn.org/stable/auto_examples/tree/plot_cost_complexity_pruning.html\n",
    "\n",
    "path = dtc.cost_complexity_pruning_path(X_train, y_train)\n",
    "\n",
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(ccp_alphas[:-1], impurities[:-1], marker = 'o', drawstyle = 'steps-post')\n",
    "\n",
    "ax.set_xlabel('effective alpha')\n",
    "\n",
    "ax.set_ylabel('total impurity of leaves')\n",
    "\n",
    "ax.set_title('Total Impurity vs effective alpha for training set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtcs = []\n",
    "\n",
    "for ccp_alpha in ccp_alphas:\n",
    "    \n",
    "    dtc = DecisionTreeClassifier(random_state = random_state, ccp_alpha = ccp_alpha)\n",
    "    \n",
    "    dtc.fit(X_train, y_train)\n",
    "    \n",
    "    dtcs.append(dtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtcs = dtcs[:-1]\n",
    "\n",
    "ccp_alphas = ccp_alphas[:-1]\n",
    "\n",
    "node_counts = [dtc.tree_.node_count for dtc in dtcs]\n",
    "\n",
    "depth = [dtc.tree_.max_depth for dtc in dtcs]\n",
    "\n",
    "fig, ax = plt.subplots(2, 1)\n",
    "\n",
    "ax[0].plot(ccp_alphas, node_counts, marker = 'o', drawstyle = 'steps-post')\n",
    "\n",
    "ax[0].set_xlabel('alpha')\n",
    "\n",
    "ax[0].set_ylabel('number of nodes')\n",
    "\n",
    "ax[0].set_title('Number of nodes vs alpha')\n",
    "\n",
    "ax[1].plot(ccp_alphas, depth, marker = 'o', drawstyle = 'steps-post')\n",
    "\n",
    "ax[1].set_xlabel('alpha')\n",
    "\n",
    "ax[1].set_ylabel('depth of tree')\n",
    "\n",
    "ax[1].set_title('Depth vs alpha')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores = [dtc.score(X_train, y_train) for dtc in dtcs]\n",
    "\n",
    "test_scores = [dtc.score(X_test, y_test) for dtc in dtcs]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_xlabel('alpha')\n",
    "\n",
    "ax.set_ylabel('accuracy')\n",
    "\n",
    "ax.set_title('Accuracy vs alpha for training and testing sets')\n",
    "\n",
    "ax.plot(ccp_alphas, train_scores, marker = 'o', label = 'train', drawstyle = 'steps-post')\n",
    "\n",
    "ax.plot(ccp_alphas, test_scores, marker = 'o', label = 'test', drawstyle = 'steps-post')\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree with gini and pruning\n",
    "\n",
    "dtc = DecisionTreeClassifier(random_state = random_state, ccp_alpha = 0.01)\n",
    "\n",
    "# DecisionTreeClassifier(*, criterion='gini', splitter='best', \n",
    "#                       max_depth=None, min_samples_split=2, min_samples_leaf=1, \n",
    "#                       min_weight_fraction_leaf=0.0, max_features=None, \n",
    "#                       random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
    "#                       class_weight=None, ccp_alpha=0.0)\n",
    "\n",
    "dtc.fit(X_train, y_train)\n",
    "\n",
    "y_train_dtc_pred = dtc.predict(X_train)\n",
    "\n",
    "y_test_dtc_pred = dtc.predict(X_test)\n",
    "\n",
    "print('Train Score:', dtc.score(X_train, y_train))\n",
    "\n",
    "print('Test Score:', dtc.score(X_test, y_test))\n",
    "\n",
    "print('Train Matthews Corr:', matthews_corrcoef(y_train, y_train_dtc_pred))\n",
    "\n",
    "print('Test Matthews Corr:', matthews_corrcoef(y_test, y_test_dtc_pred))\n",
    "\n",
    "print('--------')\n",
    "\n",
    "print('Train Confusion Matrix:')\n",
    "\n",
    "cm_train_dtc = confusion_matrix(y_train, y_train_dtc_pred, labels = classes)\n",
    "\n",
    "fig = sns.heatmap(cm_train_dtc, annot = True, fmt = 'd', cbar = False)\n",
    "\n",
    "plt.xlabel('Pedicted')\n",
    "\n",
    "plt.ylabel('True')\n",
    "\n",
    "plt.show()\n",
    "    \n",
    "print('--------')\n",
    "\n",
    "print('Test Confusion Matrix:')\n",
    "\n",
    "cm_test_dtc = confusion_matrix(y_test, y_test_dtc_pred, labels = classes)\n",
    "\n",
    "fig = sns.heatmap(cm_test_dtc, annot = True, fmt = 'd', cbar = False)\n",
    "\n",
    "plt.xlabel('Pedicted')\n",
    "\n",
    "plt.ylabel('True')\n",
    "\n",
    "plt.show()\n",
    "    \n",
    "print('--------')\n",
    "\n",
    "print('Test Classification Report:')\n",
    "\n",
    "print(classification_report(y_test, y_test_dtc_pred))\n",
    "\n",
    "report = classification_report(y_test, y_test_dtc_pred, output_dict = True)\n",
    "\n",
    "report1 = pd.DataFrame(report).transpose()\n",
    "\n",
    "report1\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/tree.html#tree\n",
    "\n",
    "#tree_data = tree.export_graphviz(dtc, out_file = None) \n",
    "\n",
    "#graph = graphviz.Source(tree_data) \n",
    "\n",
    "#graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DF.append(['dtc', 'gini', 1, \n",
    "           round(dtc.score(X_train, y_train), 5), round(dtc.score(X_test, y_test), 5), \n",
    "           round(matthews_corrcoef(y_train, y_train_dtc_pred), 5), \n",
    "           round(matthews_corrcoef(y_test, y_test_dtc_pred), 5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree with Entropy Criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree with entropy\n",
    "\n",
    "dtc = DecisionTreeClassifier(random_state = random_state, criterion = 'entropy')\n",
    "\n",
    "# DecisionTreeClassifier(*, criterion='gini', splitter='best', \n",
    "#                       max_depth=None, min_samples_split=2, min_samples_leaf=1, \n",
    "#                       min_weight_fraction_leaf=0.0, max_features=None, \n",
    "#                       random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
    "#                       class_weight=None, ccp_alpha=0.0)\n",
    "\n",
    "dtc.fit(X_train, y_train)\n",
    "\n",
    "y_train_dtc_pred = dtc.predict(X_train)\n",
    "\n",
    "y_test_dtc_pred = dtc.predict(X_test)\n",
    "\n",
    "print('Train Score:', dtc.score(X_train, y_train))\n",
    "\n",
    "print('Test Score:', dtc.score(X_test, y_test))\n",
    "\n",
    "print('Train Matthews Corr:', matthews_corrcoef(y_train, y_train_dtc_pred))\n",
    "\n",
    "print('Test Matthews Corr:', matthews_corrcoef(y_test, y_test_dtc_pred))\n",
    "\n",
    "print('--------')\n",
    "\n",
    "print('Train Confusion Matrix:')\n",
    "\n",
    "cm_train_dtc = confusion_matrix(y_train, y_train_dtc_pred, labels = classes)\n",
    "\n",
    "fig = sns.heatmap(cm_train_dtc, annot = True, fmt = 'd', cbar = False)\n",
    "\n",
    "plt.xlabel('Pedicted')\n",
    "\n",
    "plt.ylabel('True')\n",
    "\n",
    "plt.show()\n",
    "    \n",
    "print('--------')\n",
    "\n",
    "print('Test Confusion Matrix:')\n",
    "\n",
    "cm_test_dtc = confusion_matrix(y_test, y_test_dtc_pred, labels = classes)\n",
    "\n",
    "fig = sns.heatmap(cm_test_dtc, annot = True, fmt = 'd', cbar = False)\n",
    "\n",
    "plt.xlabel('Pedicted')\n",
    "\n",
    "plt.ylabel('True')\n",
    "\n",
    "plt.show()\n",
    "    \n",
    "print('--------')\n",
    "\n",
    "print('Test Classification Report:')\n",
    "\n",
    "print(classification_report(y_test, y_test_dtc_pred))\n",
    "\n",
    "report = classification_report(y_test, y_test_dtc_pred, output_dict = True)\n",
    "\n",
    "report1 = pd.DataFrame(report).transpose()\n",
    "\n",
    "report1\n",
    "\n",
    "#tree_data = tree.export_graphviz(dtc, out_file = None) \n",
    "\n",
    "#graph = graphviz.Source(tree_data) \n",
    "\n",
    "#graph  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.append(['dtc', 'entropy', 0, \n",
    "           round(dtc.score(X_train, y_train), 5), round(dtc.score(X_test, y_test), 5), \n",
    "           round(matthews_corrcoef(y_train, y_train_dtc_pred), 5), \n",
    "           round(matthews_corrcoef(y_test, y_test_dtc_pred), 5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = dtc.cost_complexity_pruning_path(X_train, y_train)\n",
    "\n",
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(ccp_alphas[:-1], impurities[:-1], marker = 'o', drawstyle = 'steps-post')\n",
    "\n",
    "ax.set_xlabel('effective alpha')\n",
    "\n",
    "ax.set_ylabel('total impurity of leaves')\n",
    "\n",
    "ax.set_title('Total Impurity vs effective alpha for training set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtcs = []\n",
    "\n",
    "for ccp_alpha in ccp_alphas:\n",
    "    \n",
    "    dtc = DecisionTreeClassifier(random_state = random_state, ccp_alpha = ccp_alpha)\n",
    "    \n",
    "    dtc.fit(X_train, y_train)\n",
    "    \n",
    "    dtcs.append(dtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtcs = dtcs[:-1]\n",
    "\n",
    "ccp_alphas = ccp_alphas[:-1]\n",
    "\n",
    "node_counts = [dtc.tree_.node_count for dtc in dtcs]\n",
    "\n",
    "depth = [dtc.tree_.max_depth for dtc in dtcs]\n",
    "\n",
    "fig, ax = plt.subplots(2, 1)\n",
    "\n",
    "ax[0].plot(ccp_alphas, node_counts, marker = 'o', drawstyle = 'steps-post')\n",
    "\n",
    "ax[0].set_xlabel('alpha')\n",
    "\n",
    "ax[0].set_ylabel('number of nodes')\n",
    "\n",
    "ax[0].set_title('Number of nodes vs alpha')\n",
    "\n",
    "ax[1].plot(ccp_alphas, depth, marker='o', drawstyle='steps-post')\n",
    "\n",
    "ax[1].set_xlabel('alpha')\n",
    "\n",
    "ax[1].set_ylabel('depth of tree')\n",
    "\n",
    "ax[1].set_title('Depth vs alpha')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores = [dtc.score(X_train, y_train) for dtc in dtcs]\n",
    "\n",
    "test_scores = [dtc.score(X_test, y_test) for dtc in dtcs]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_xlabel('alpha')\n",
    "\n",
    "ax.set_ylabel('accuracy')\n",
    "\n",
    "ax.set_title('Accuracy vs alpha for training and testing sets')\n",
    "\n",
    "ax.plot(ccp_alphas, train_scores, marker = 'o', label = 'train', drawstyle = 'steps-post')\n",
    "\n",
    "ax.plot(ccp_alphas, test_scores, marker = 'o', label = 'test', drawstyle = 'steps-post')\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree with entropy and pruning\n",
    "\n",
    "dtc = DecisionTreeClassifier(random_state = random_state, criterion = 'entropy', ccp_alpha = 0.03)\n",
    "\n",
    "# DecisionTreeClassifier(*, criterion='gini', splitter='best', \n",
    "#                       max_depth=None, min_samples_split=2, min_samples_leaf=1, \n",
    "#                       min_weight_fraction_leaf=0.0, max_features=None, \n",
    "#                       random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
    "#                       class_weight=None, ccp_alpha=0.0)\n",
    "\n",
    "dtc.fit(X_train, y_train)\n",
    "\n",
    "y_train_dtc_pred = dtc.predict(X_train)\n",
    "\n",
    "y_test_dtc_pred = dtc.predict(X_test)\n",
    "\n",
    "print('Train Score:', dtc.score(X_train, y_train))\n",
    "\n",
    "print('Test Score:', dtc.score(X_test, y_test))\n",
    "\n",
    "print('Train Matthews Corr:', matthews_corrcoef(y_train, y_train_dtc_pred))\n",
    "\n",
    "print('Test Matthews Corr:', matthews_corrcoef(y_test, y_test_dtc_pred))\n",
    "\n",
    "print('--------')\n",
    "\n",
    "print('Train Confusion Matrix:')\n",
    "\n",
    "cm_train_dtc = confusion_matrix(y_train, y_train_dtc_pred, labels = classes)\n",
    "\n",
    "fig = sns.heatmap(cm_train_dtc, annot = True, fmt = 'd', cbar = False)\n",
    "\n",
    "plt.xlabel('Pedicted')\n",
    "\n",
    "plt.ylabel('True')\n",
    "\n",
    "plt.show()\n",
    "    \n",
    "print('--------')\n",
    "\n",
    "print('Test Confusion Matrix:')\n",
    "\n",
    "cm_test_dtc = confusion_matrix(y_test, y_test_dtc_pred, labels = classes)\n",
    "\n",
    "fig = sns.heatmap(cm_test_dtc, annot = True, fmt = 'd', cbar = False)\n",
    "\n",
    "plt.xlabel('Pedicted')\n",
    "\n",
    "plt.ylabel('True')\n",
    "\n",
    "plt.show()\n",
    "    \n",
    "print('--------')\n",
    "\n",
    "print('Test Classification Report:')\n",
    "\n",
    "print(classification_report(y_test, y_test_dtc_pred))\n",
    "\n",
    "report = classification_report(y_test, y_test_dtc_pred, output_dict = True)\n",
    "\n",
    "report1 = pd.DataFrame(report).transpose()\n",
    "\n",
    "report1\n",
    "\n",
    "#tree_data = tree.export_graphviz(dtc, out_file = None) \n",
    "\n",
    "#graph = graphviz.Source(tree_data) \n",
    "\n",
    "#graph  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DF.append(['dtc', 'entropy', 1, \n",
    "           round(dtc.score(X_train, y_train), 5), round(dtc.score(X_test, y_test), 5), \n",
    "           round(matthews_corrcoef(y_train, y_train_dtc_pred), 5), \n",
    "           round(matthews_corrcoef(y_test, y_test_dtc_pred), 5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra Tree with Gini Criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra tree with gini\n",
    "\n",
    "etc = ExtraTreeClassifier(random_state = random_state)\n",
    "\n",
    "# ExtraTreeClassifier(*, criterion='gini', splitter='random', max_depth=None, \n",
    "#                    min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
    "#                    max_features='sqrt', random_state=None, max_leaf_nodes=None, \n",
    "#                    min_impurity_decrease=0.0, class_weight=None, ccp_alpha=0.0)\n",
    "\n",
    "etc.fit(X_train, y_train)\n",
    "\n",
    "y_train_etc_pred = etc.predict(X_train)\n",
    "\n",
    "y_test_etc_pred = etc.predict(X_test)\n",
    "\n",
    "print('Train Score:', etc.score(X_train, y_train))\n",
    "\n",
    "print('Test Score:', etc.score(X_test, y_test))\n",
    "\n",
    "print('Train Matthews Corr:', matthews_corrcoef(y_train, y_train_etc_pred))\n",
    "\n",
    "print('Test Matthews Corr:', matthews_corrcoef(y_test, y_test_etc_pred))\n",
    "\n",
    "print('--------')\n",
    "\n",
    "print('Train Confusion Matrix:')\n",
    "\n",
    "cm_train_etc = confusion_matrix(y_train, y_train_etc_pred, labels = classes)\n",
    "\n",
    "fig = sns.heatmap(cm_train_etc, annot = True, fmt = 'd', cbar = False)\n",
    "\n",
    "plt.xlabel('Pedicted')\n",
    "\n",
    "plt.ylabel('True')\n",
    "\n",
    "plt.show()\n",
    "    \n",
    "print('--------')\n",
    "\n",
    "print('Test Confusion Matrix:')\n",
    "\n",
    "cm_test_etc = confusion_matrix(y_test, y_test_etc_pred, labels = classes)\n",
    "\n",
    "fig = sns.heatmap(cm_test_etc, annot = True, fmt = 'd', cbar = False)\n",
    "\n",
    "plt.xlabel('Pedicted')\n",
    "\n",
    "plt.ylabel('True')\n",
    "\n",
    "plt.show()\n",
    "    \n",
    "print('--------')\n",
    "\n",
    "print('Test Classification Report:')\n",
    "\n",
    "print(classification_report(y_test,y_test_etc_pred))\n",
    "\n",
    "report = classification_report(y_test,y_test_etc_pred, output_dict = True)\n",
    "\n",
    "report1 = pd.DataFrame(report).transpose()\n",
    "\n",
    "report1\n",
    "\n",
    "#tree_data = tree.export_graphviz(dtc, out_file = None) \n",
    "\n",
    "#graph = graphviz.Source(tree_data) \n",
    "\n",
    "#graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.append(['etc', 'gini', 0, \n",
    "           round(etc.score(X_train, y_train), 5), round(etc.score(X_test, y_test), 5), \n",
    "           round(matthews_corrcoef(y_train, y_train_etc_pred), 5), \n",
    "           round(matthews_corrcoef(y_test, y_test_etc_pred), 5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = etc.cost_complexity_pruning_path(X_train, y_train)\n",
    "\n",
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(ccp_alphas[:-1], impurities[:-1], marker = 'o', drawstyle = 'steps-post')\n",
    "\n",
    "ax.set_xlabel('effective alpha')\n",
    "\n",
    "ax.set_ylabel('total impurity of leaves')\n",
    "\n",
    "ax.set_title('Total Impurity vs effective alpha for training set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etcs = []\n",
    "\n",
    "for ccp_alpha in ccp_alphas:\n",
    "    \n",
    "    etc = ExtraTreeClassifier(random_state = random_state, ccp_alpha = ccp_alpha)\n",
    "    \n",
    "    etc.fit(X_train, y_train)\n",
    "    \n",
    "    etcs.append(etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etcs = etcs[:-1]\n",
    "\n",
    "ccp_alphas = ccp_alphas[:-1]\n",
    "\n",
    "node_counts = [etc.tree_.node_count for etc in etcs]\n",
    "\n",
    "depth = [etc.tree_.max_depth for etc in etcs]\n",
    "\n",
    "fig, ax = plt.subplots(2, 1)\n",
    "\n",
    "ax[0].plot(ccp_alphas, node_counts, marker = 'o', drawstyle = 'steps-post')\n",
    "\n",
    "ax[0].set_xlabel('alpha')\n",
    "\n",
    "ax[0].set_ylabel('number of nodes')\n",
    "\n",
    "ax[0].set_title('Number of nodes vs alpha')\n",
    "\n",
    "ax[1].plot(ccp_alphas, depth, marker='o', drawstyle='steps-post')\n",
    "\n",
    "ax[1].set_xlabel('alpha')\n",
    "\n",
    "ax[1].set_ylabel('depth of tree')\n",
    "\n",
    "ax[1].set_title('Depth vs alpha')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores = [etc.score(X_train, y_train) for etc in etcs]\n",
    "\n",
    "test_scores = [etc.score(X_test, y_test) for etc in etcs]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_xlabel('alpha')\n",
    "\n",
    "ax.set_ylabel('accuracy')\n",
    "\n",
    "ax.set_title('Accuracy vs alpha for training and testing sets')\n",
    "\n",
    "ax.plot(ccp_alphas, train_scores, marker = 'o', label = 'train', drawstyle = 'steps-post')\n",
    "\n",
    "ax.plot(ccp_alphas, test_scores, marker = 'o', label = 'test', drawstyle = 'steps-post')\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra tree with gini and pruning\n",
    "\n",
    "etc = DecisionTreeClassifier(random_state = random_state, ccp_alpha = 0.01)\n",
    "\n",
    "# DecisionTreeClassifier(*, criterion='gini', splitter='best', \n",
    "#                       max_depth=None, min_samples_split=2, min_samples_leaf=1, \n",
    "#                       min_weight_fraction_leaf=0.0, max_features=None, \n",
    "#                       random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
    "#                       class_weight=None, ccp_alpha=0.0)\n",
    "\n",
    "etc.fit(X_train, y_train)\n",
    "\n",
    "y_train_etc_pred = etc.predict(X_train)\n",
    "\n",
    "y_test_etc_pred = etc.predict(X_test)\n",
    "\n",
    "print('Train Score:', etc.score(X_train, y_train))\n",
    "\n",
    "print('Test Score:', etc.score(X_test, y_test))\n",
    "\n",
    "print('Train Matthews Corr:', matthews_corrcoef(y_train, y_train_etc_pred))\n",
    "\n",
    "print('Test Matthews Corr:', matthews_corrcoef(y_test, y_test_etc_pred))\n",
    "\n",
    "print('--------')\n",
    "\n",
    "print('Train Confusion Matrix:')\n",
    "\n",
    "cm_train_etc = confusion_matrix(y_train, y_train_etc_pred, labels = classes)\n",
    "\n",
    "fig = sns.heatmap(cm_train_etc, annot = True, fmt = 'd', cbar = False)\n",
    "\n",
    "plt.xlabel('Pedicted')\n",
    "\n",
    "plt.ylabel('True')\n",
    "\n",
    "plt.show()\n",
    "    \n",
    "print('--------')\n",
    "\n",
    "print('Test Confusion Matrix:')\n",
    "\n",
    "cm_test_etc = confusion_matrix(y_test, y_test_etc_pred, labels = classes)\n",
    "\n",
    "fig = sns.heatmap(cm_test_etc, annot = True, fmt = 'd', cbar = False)\n",
    "\n",
    "plt.xlabel('Pedicted')\n",
    "\n",
    "plt.ylabel('True')\n",
    "\n",
    "plt.show()\n",
    "    \n",
    "print('--------')\n",
    "\n",
    "print('Test Classification Report:')\n",
    "\n",
    "print(classification_report(y_test, y_test_etc_pred))\n",
    "\n",
    "report = classification_report(y_test, y_test_etc_pred, output_dict = True)\n",
    "\n",
    "report1 = pd.DataFrame(report).transpose()\n",
    "\n",
    "report1\n",
    "\n",
    "#tree_data = tree.export_graphviz(etc, out_file = None) \n",
    "\n",
    "#graph = graphviz.Source(tree_data) \n",
    "\n",
    "#graph  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DF.append(['etc', 'gini', 1, \n",
    "           round(etc.score(X_train, y_train), 5), round(etc.score(X_test, y_test), 5), \n",
    "           round(matthews_corrcoef(y_train, y_train_etc_pred), 5), \n",
    "           round(matthews_corrcoef(y_test, y_test_etc_pred), 5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra Tree with Entropy Criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra tree with entropy\n",
    "\n",
    "etc = ExtraTreeClassifier(random_state = random_state, criterion = 'entropy')\n",
    "\n",
    "# ExtraTreeClassifier(*, criterion='gini', splitter='random', max_depth=None, \n",
    "#                    min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
    "#                    max_features='sqrt', random_state=None, max_leaf_nodes=None, \n",
    "#                    min_impurity_decrease=0.0, class_weight=None, ccp_alpha=0.0)\n",
    "\n",
    "etc.fit(X_train, y_train)\n",
    "\n",
    "y_train_etc_pred = etc.predict(X_train)\n",
    "\n",
    "y_test_etc_pred = etc.predict(X_test)\n",
    "\n",
    "print('Train Score:', etc.score(X_train, y_train))\n",
    "\n",
    "print('Test Score:', etc.score(X_test, y_test))\n",
    "\n",
    "print('Train Matthews Corr:', matthews_corrcoef(y_train, y_train_etc_pred))\n",
    "\n",
    "print('Test Matthews Corr:', matthews_corrcoef(y_test, y_test_etc_pred))\n",
    "\n",
    "print('--------')\n",
    "\n",
    "print('Train Confusion Matrix:')\n",
    "\n",
    "cm_train_etc = confusion_matrix(y_train, y_train_etc_pred, labels = classes)\n",
    "\n",
    "fig = sns.heatmap(cm_train_etc, annot = True, fmt = 'd', cbar = False)\n",
    "\n",
    "plt.xlabel('Pedicted')\n",
    "\n",
    "plt.ylabel('True')\n",
    "\n",
    "plt.show()\n",
    "    \n",
    "print('--------')\n",
    "\n",
    "print('Test Confusion Matrix:')\n",
    "\n",
    "cm_test_etc = confusion_matrix(y_test, y_test_etc_pred, labels = classes)\n",
    "\n",
    "fig = sns.heatmap(cm_test_etc, annot = True, fmt = 'd', cbar = False)\n",
    "\n",
    "plt.xlabel('Pedicted')\n",
    "\n",
    "plt.ylabel('True')\n",
    "\n",
    "plt.show()\n",
    "    \n",
    "print('--------')\n",
    "\n",
    "print('Test Classification Report:')\n",
    "\n",
    "print(classification_report(y_test,y_test_etc_pred))\n",
    "\n",
    "report = classification_report(y_test,y_test_etc_pred, output_dict = True)\n",
    "\n",
    "report1 = pd.DataFrame(report).transpose()\n",
    "\n",
    "report1\n",
    "\n",
    "#tree_data = tree.export_graphviz(dtc, out_file = None) \n",
    "\n",
    "#graph = graphviz.Source(tree_data) \n",
    "\n",
    "#graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.append(['etc', 'entropy', 0, \n",
    "           round(etc.score(X_train, y_train), 5), round(etc.score(X_test, y_test), 5), \n",
    "           round(matthews_corrcoef(y_train, y_train_etc_pred), 5), \n",
    "           round(matthews_corrcoef(y_test, y_test_etc_pred), 5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = etc.cost_complexity_pruning_path(X_train, y_train)\n",
    "\n",
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(ccp_alphas[:-1], impurities[:-1], marker = 'o', drawstyle = 'steps-post')\n",
    "\n",
    "ax.set_xlabel('effective alpha')\n",
    "\n",
    "ax.set_ylabel('total impurity of leaves')\n",
    "\n",
    "ax.set_title('Total Impurity vs effective alpha for training set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etcs = []\n",
    "\n",
    "for ccp_alpha in ccp_alphas:\n",
    "    \n",
    "    etc = ExtraTreeClassifier(random_state = random_state, ccp_alpha = ccp_alpha)\n",
    "    \n",
    "    etc.fit(X_train, y_train)\n",
    "    \n",
    "    etcs.append(etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etcs = etcs[:-1]\n",
    "\n",
    "ccp_alphas = ccp_alphas[:-1]\n",
    "\n",
    "node_counts = [etc.tree_.node_count for etc in etcs]\n",
    "\n",
    "depth = [etc.tree_.max_depth for etc in etcs]\n",
    "\n",
    "fig, ax = plt.subplots(2, 1)\n",
    "\n",
    "ax[0].plot(ccp_alphas, node_counts, marker = 'o', drawstyle = 'steps-post')\n",
    "\n",
    "ax[0].set_xlabel('alpha')\n",
    "\n",
    "ax[0].set_ylabel('number of nodes')\n",
    "\n",
    "ax[0].set_title('Number of nodes vs alpha')\n",
    "\n",
    "ax[1].plot(ccp_alphas, depth, marker='o', drawstyle='steps-post')\n",
    "\n",
    "ax[1].set_xlabel('alpha')\n",
    "\n",
    "ax[1].set_ylabel('depth of tree')\n",
    "\n",
    "ax[1].set_title('Depth vs alpha')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores = [etc.score(X_train, y_train) for etc in etcs]\n",
    "\n",
    "test_scores = [etc.score(X_test, y_test) for etc in etcs]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_xlabel('alpha')\n",
    "\n",
    "ax.set_ylabel('accuracy')\n",
    "\n",
    "ax.set_title('Accuracy vs alpha for training and testing sets')\n",
    "\n",
    "ax.plot(ccp_alphas, train_scores, marker = 'o', label = 'train', drawstyle = 'steps-post')\n",
    "\n",
    "ax.plot(ccp_alphas, test_scores, marker = 'o', label = 'test', drawstyle = 'steps-post')\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra tree with entropy and pruning\n",
    "\n",
    "etc = ExtraTreeClassifier(random_state = random_state, criterion = 'entropy', ccp_alpha = 0.02)\n",
    "\n",
    "# ExtraTreeClassifier(*, criterion='gini', splitter='random', max_depth=None, \n",
    "#                    min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
    "#                    max_features='sqrt', random_state=None, max_leaf_nodes=None, \n",
    "#                    min_impurity_decrease=0.0, class_weight=None, ccp_alpha=0.0)\n",
    "\n",
    "etc.fit(X_train, y_train)\n",
    "\n",
    "y_train_etc_pred = etc.predict(X_train)\n",
    "\n",
    "y_test_etc_pred = etc.predict(X_test)\n",
    "\n",
    "print('Train Score:', etc.score(X_train, y_train))\n",
    "\n",
    "print('Test Score:', etc.score(X_test, y_test))\n",
    "\n",
    "print('Train Matthews Corr:', matthews_corrcoef(y_train, y_train_etc_pred))\n",
    "\n",
    "print('Test Matthews Corr:', matthews_corrcoef(y_test, y_test_etc_pred))\n",
    "\n",
    "print('--------')\n",
    "\n",
    "print('Train Confusion Matrix:')\n",
    "\n",
    "cm_train_etc = confusion_matrix(y_train, y_train_etc_pred, labels = classes)\n",
    "\n",
    "fig = sns.heatmap(cm_train_etc, annot = True, fmt = 'd', cbar = False)\n",
    "\n",
    "plt.xlabel('Pedicted')\n",
    "\n",
    "plt.ylabel('True')\n",
    "\n",
    "plt.show()\n",
    "    \n",
    "print('--------')\n",
    "\n",
    "print('Test Confusion Matrix:')\n",
    "\n",
    "cm_test_etc = confusion_matrix(y_test, y_test_etc_pred, labels = classes)\n",
    "\n",
    "fig = sns.heatmap(cm_test_etc, annot = True, fmt = 'd', cbar = False)\n",
    "\n",
    "plt.xlabel('Pedicted')\n",
    "\n",
    "plt.ylabel('True')\n",
    "\n",
    "plt.show()\n",
    "    \n",
    "print('--------')\n",
    "\n",
    "print('Test Classification Report:')\n",
    "\n",
    "print(classification_report(y_test, y_test_etc_pred))\n",
    "\n",
    "report = classification_report(y_test, y_test_etc_pred, output_dict = True)\n",
    "\n",
    "report1 = pd.DataFrame(report).transpose()\n",
    "\n",
    "report1\n",
    "\n",
    "#tree_data = tree.export_graphviz(etc, out_file = None) \n",
    "\n",
    "#graph = graphviz.Source(tree_data) \n",
    "\n",
    "#graph  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DF.append(['etc', 'entropy', 1, \n",
    "           round(etc.score(X_train, y_train), 5), round(etc.score(X_test, y_test), 5), \n",
    "           round(matthews_corrcoef(y_train, y_train_etc_pred), 5), \n",
    "           round(matthews_corrcoef(y_test, y_test_etc_pred), 5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bagging\n",
    "\n",
    "bc = BaggingClassifier(random_state = random_state)\n",
    "\n",
    "# BaggingClassifier(base_estimator=None, n_estimators=10, max_samples=1.0, max_features=1.0, \n",
    "#                  bootstrap=True, bootstrap_features=False, oob_score=False, warm_start=False, \n",
    "#                 n_jobs=None, random_state=None, verbose=0)\n",
    "\n",
    "bc.fit(X_train, y_train)\n",
    "\n",
    "y_train_bc_pred = bc.predict(X_train)\n",
    "\n",
    "y_test_bc_pred = bc.predict(X_test)\n",
    "\n",
    "print('Train Score:', bc.score(X_train, y_train))\n",
    "\n",
    "print('Test Score:', bc.score(X_test, y_test))\n",
    "\n",
    "print('Train Matthews Corr:', matthews_corrcoef(y_train, y_train_bc_pred))\n",
    "\n",
    "print('Test Matthews Corr:', matthews_corrcoef(y_test, y_test_bc_pred))\n",
    "\n",
    "print('--------')\n",
    "\n",
    "print('Train Confusion Matrix:')\n",
    "\n",
    "cm_train_bc = confusion_matrix(y_train, y_train_bc_pred, labels = classes)\n",
    "\n",
    "fig = sns.heatmap(cm_train_bc, annot = True, fmt = 'd', cbar = False)\n",
    "\n",
    "plt.xlabel('Pedicted')\n",
    "\n",
    "plt.ylabel('True')\n",
    "\n",
    "plt.show()\n",
    "    \n",
    "print('--------')\n",
    "\n",
    "print('Test Confusion Matrix:')\n",
    "\n",
    "cm_test_bc = confusion_matrix(y_test,y_test_bc_pred, labels = classes)\n",
    "\n",
    "fig = sns.heatmap(cm_test_bc, annot = True, fmt = 'd', cbar = False)\n",
    "\n",
    "plt.xlabel('Pedicted')\n",
    "\n",
    "plt.ylabel('True')\n",
    "\n",
    "plt.show()\n",
    "    \n",
    "print('--------')\n",
    "\n",
    "print('Test Classification Report:')\n",
    "\n",
    "print(classification_report(y_test, y_test_bc_pred))\n",
    "\n",
    "report = classification_report(y_test, y_test_bc_pred, output_dict = True)\n",
    "\n",
    "report1 = pd.DataFrame(report).transpose()\n",
    "\n",
    "report1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.append(['bc', 'na', 'na', \n",
    "           round(bc.score(X_train, y_train), 5), round(bc.score(X_test, y_test), 5), \n",
    "           round(matthews_corrcoef(y_train, y_train_bc_pred), 5), \n",
    "           round(matthews_corrcoef(y_test, y_test_bc_pred), 5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest with Gini Criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest with gini\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators = 50, random_state = random_state)\n",
    "\n",
    "# RandomForestClassifier(n_estimators=100, *, criterion='gini', max_depth=None, \n",
    "#                       min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
    "#                       max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
    "#                       bootstrap=True, oob_score=False, n_jobs=None, \n",
    "#                       random_state=None, verbose=0, warm_start=False, \n",
    "#                       class_weight=None, ccp_alpha=0.0, max_samples=None)\n",
    "\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "y_train_rfc_pred = rfc.predict(X_train)\n",
    "\n",
    "y_test_rfc_pred = rfc.predict(X_test)\n",
    "\n",
    "print('Train Score:', rfc.score(X_train, y_train))\n",
    "\n",
    "print('Test Score:', rfc.score(X_test, y_test))\n",
    "\n",
    "print('---------')\n",
    "\n",
    "print('Train Confusion Matrix:')\n",
    "\n",
    "cm_train_rfc = confusion_matrix(y_train, y_train_rfc_pred, labels = classes)\n",
    "\n",
    "fig = sns.heatmap(cm_train_rfc, annot = True, fmt = 'd', cbar = False)\n",
    "\n",
    "plt.xlabel('Pedicted')\n",
    "\n",
    "plt.ylabel('True')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print('--------')\n",
    "    \n",
    "print('Test Confusion Matrix:')\n",
    "\n",
    "cm_test_rfc = confusion_matrix(y_test, y_test_rfc_pred, labels = classes)\n",
    "\n",
    "fig = sns.heatmap(cm_test_rfc, annot = True, fmt = 'd', cbar = False)\n",
    "\n",
    "plt.xlabel('Pedicted')\n",
    "\n",
    "plt.ylabel('True')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print('--------')\n",
    "\n",
    "print('Test Classification Report:')\n",
    "\n",
    "print(classification_report(y_test, y_test_rfc_pred))\n",
    "\n",
    "report = classification_report(y_test, y_test_rfc_pred, output_dict = True)\n",
    "\n",
    "report1 = pd.DataFrame(report).transpose()\n",
    "\n",
    "report1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.append(['rfc', 'gini', 0, \n",
    "           round(rfc.score(X_train, y_train), 5), round(rfc.score(X_test, y_test), 5), \n",
    "           round(matthews_corrcoef(y_train, y_train_rfc_pred), 5), \n",
    "           round(matthews_corrcoef(y_test, y_test_rfc_pred), 5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest with gini and pruning\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators = 50, random_state = random_state, ccp_alpha = 0.01)\n",
    "\n",
    "# RandomForestClassifier(n_estimators=100, *, criterion='gini', max_depth=None, \n",
    "#                       min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
    "#                       max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
    "#                       bootstrap=True, oob_score=False, n_jobs=None, \n",
    "#                       random_state=None, verbose=0, warm_start=False, \n",
    "#                       class_weight=None, ccp_alpha=0.0, max_samples=None)\n",
    "\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "y_train_rfc_pred = rfc.predict(X_train)\n",
    "\n",
    "y_test_rfc_pred = rfc.predict(X_test)\n",
    "\n",
    "print('Train Score:', rfc.score(X_train, y_train))\n",
    "\n",
    "print('Test Score:', rfc.score(X_test, y_test))\n",
    "\n",
    "print('Train Matthews Corr:', matthews_corrcoef(y_train, y_train_rfc_pred))\n",
    "\n",
    "print('Test Matthews Corr:', matthews_corrcoef(y_test, y_test_rfc_pred))\n",
    "\n",
    "print('---------')\n",
    "\n",
    "print('Train Confusion Matrix:')\n",
    "\n",
    "cm_train_rfc = confusion_matrix(y_train, y_train_rfc_pred, labels = classes)\n",
    "\n",
    "fig = sns.heatmap(cm_train_rfc, annot = True, fmt = 'd', cbar = False)\n",
    "\n",
    "plt.xlabel('Pedicted')\n",
    "\n",
    "plt.ylabel('True')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print('--------')\n",
    "    \n",
    "print('Test Confusion Matrix:')\n",
    "\n",
    "cm_test_rfc = confusion_matrix(y_test, y_test_rfc_pred, labels = classes)\n",
    "\n",
    "fig = sns.heatmap(cm_test_rfc, annot = True, fmt = 'd', cbar = False)\n",
    "\n",
    "plt.xlabel('Pedicted')\n",
    "\n",
    "plt.ylabel('True')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print('--------')\n",
    "\n",
    "print('Test Classification Report:')\n",
    "\n",
    "print(classification_report(y_test, y_test_rfc_pred))\n",
    "\n",
    "report = classification_report(y_test, y_test_rfc_pred, output_dict = True)\n",
    "\n",
    "report1 = pd.DataFrame(report).transpose()\n",
    "\n",
    "report1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.append(['rfc', 'gini', 1, \n",
    "           round(rfc.score(X_train, y_train), 5), round(rfc.score(X_test, y_test), 5), \n",
    "           round(matthews_corrcoef(y_train, y_train_rfc_pred), 5), \n",
    "           round(matthews_corrcoef(y_test, y_test_rfc_pred), 5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest with Entropy Criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest with entropy\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators = 50, random_state = random_state, criterion = 'entropy')\n",
    "\n",
    "# RandomForestClassifier(n_estimators=100, *, criterion='gini', max_depth=None, \n",
    "#                       min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
    "#                       max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
    "#                       bootstrap=True, oob_score=False, n_jobs=None, \n",
    "#                       random_state=None, verbose=0, warm_start=False, \n",
    "#                       class_weight=None, ccp_alpha=0.0, max_samples=None)\n",
    "\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "y_train_rfc_pred = rfc.predict(X_train)\n",
    "\n",
    "y_test_rfc_pred = rfc.predict(X_test)\n",
    "\n",
    "print('Train Score:', rfc.score(X_train, y_train))\n",
    "\n",
    "print('Test Score:', rfc.score(X_test, y_test))\n",
    "\n",
    "print('Train Matthews Corr:', matthews_corrcoef(y_train, y_train_rfc_pred))\n",
    "\n",
    "print('Test Matthews Corr:', matthews_corrcoef(y_test, y_test_rfc_pred))\n",
    "\n",
    "\n",
    "print('---------')\n",
    "\n",
    "print('Train Confusion Matrix:')\n",
    "\n",
    "cm_train_rfc = confusion_matrix(y_train, y_train_rfc_pred, labels = classes)\n",
    "\n",
    "fig = sns.heatmap(cm_train_rfc, annot = True, fmt = 'd', cbar = False)\n",
    "\n",
    "plt.xlabel('Pedicted')\n",
    "\n",
    "plt.ylabel('True')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print('--------')\n",
    "    \n",
    "print('Test Confusion Matrix:')\n",
    "\n",
    "cm_test_rfc = confusion_matrix(y_test, y_test_rfc_pred, labels = classes)\n",
    "\n",
    "fig = sns.heatmap(cm_test_rfc, annot = True, fmt = 'd', cbar = False)\n",
    "\n",
    "plt.xlabel('Pedicted')\n",
    "\n",
    "plt.ylabel('True')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print('--------')\n",
    "\n",
    "print('Test Classification Report:')\n",
    "\n",
    "print(classification_report(y_test, y_test_rfc_pred))\n",
    "\n",
    "report = classification_report(y_test, y_test_rfc_pred, output_dict = True)\n",
    "\n",
    "report1 = pd.DataFrame(report).transpose()\n",
    "\n",
    "report1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.append(['rfc', 'entropy', 0, \n",
    "           round(rfc.score(X_train, y_train), 5), round(rfc.score(X_test, y_test), 5), \n",
    "           round(matthews_corrcoef(y_train, y_train_rfc_pred), 5), \n",
    "           round(matthews_corrcoef(y_test, y_test_rfc_pred), 5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest with entropy and pruning\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators = 50, random_state = random_state, criterion = 'entropy',\n",
    "                             ccp_alpha = 0.03)\n",
    "\n",
    "# RandomForestClassifier(n_estimators=100, *, criterion='gini', max_depth=None, \n",
    "#                       min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
    "#                       max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
    "#                       bootstrap=True, oob_score=False, n_jobs=None, \n",
    "#                       random_state=None, verbose=0, warm_start=False, \n",
    "#                       class_weight=None, ccp_alpha=0.0, max_samples=None)\n",
    "\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "y_train_rfc_pred = rfc.predict(X_train)\n",
    "\n",
    "y_test_rfc_pred = rfc.predict(X_test)\n",
    "\n",
    "print('Train Score:', rfc.score(X_train, y_train))\n",
    "\n",
    "print('Test Score:', rfc.score(X_test, y_test))\n",
    "\n",
    "print('Train Matthews Corr:', matthews_corrcoef(y_train, y_train_rfc_pred))\n",
    "\n",
    "print('Test Matthews Corr:', matthews_corrcoef(y_test, y_test_rfc_pred))\n",
    "\n",
    "print('---------')\n",
    "\n",
    "print('Train Confusion Matrix:')\n",
    "\n",
    "cm_train_rfc = confusion_matrix(y_train, y_train_rfc_pred, labels = classes)\n",
    "\n",
    "fig = sns.heatmap(cm_train_rfc, annot = True, fmt = 'd', cbar = False)\n",
    "\n",
    "plt.xlabel('Pedicted')\n",
    "\n",
    "plt.ylabel('True')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print('--------')\n",
    "    \n",
    "print('Test Confusion Matrix:')\n",
    "\n",
    "cm_test_rfc = confusion_matrix(y_test, y_test_rfc_pred, labels = classes)\n",
    "\n",
    "fig = sns.heatmap(cm_test_rfc, annot = True, fmt = 'd', cbar = False)\n",
    "\n",
    "plt.xlabel('Pedicted')\n",
    "\n",
    "plt.ylabel('True')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print('--------')\n",
    "\n",
    "print('Test Classification Report:')\n",
    "\n",
    "print(classification_report(y_test, y_test_rfc_pred))\n",
    "\n",
    "report = classification_report(y_test, y_test_rfc_pred, output_dict = True)\n",
    "\n",
    "report1 = pd.DataFrame(report).transpose()\n",
    "\n",
    "report1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.append(['rfc', 'entropy', 1, \n",
    "           round(rfc.score(X_train, y_train), 5), round(rfc.score(X_test, y_test), 5), \n",
    "           round(matthews_corrcoef(y_train, y_train_rfc_pred), 5), \n",
    "           round(matthews_corrcoef(y_test, y_test_rfc_pred), 5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Trees "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra Trees  with Gini Criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra trees with gini\n",
    "\n",
    "etsc = ExtraTreesClassifier(n_estimators = 50, random_state = random_state)\n",
    "\n",
    "# ExtraTreesClassifier(n_estimators=100, *, criterion='gini', max_depth=None, \n",
    "#                     min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
    "#                     max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
    "#                     bootstrap=False, oob_score=False, n_jobs=None, \n",
    "#                     random_state=None, verbose=0, warm_start=False, class_weight=None, \n",
    "#                     ccp_alpha=0.0, max_samples=None)\n",
    "\n",
    "etsc.fit(X_train, y_train)\n",
    "\n",
    "y_train_etsc_pred = etsc.predict(X_train)\n",
    "\n",
    "y_test_etsc_pred = etsc.predict(X_test)\n",
    "\n",
    "print('Train Score:', etsc.score(X_train, y_train))\n",
    "\n",
    "print('Test Score:', etsc.score(X_test, y_test))\n",
    "\n",
    "print('Train Matthews Corr:', matthews_corrcoef(y_train, y_train_etsc_pred))\n",
    "\n",
    "print('Test Matthews Corr:', matthews_corrcoef(y_test, y_test_etsc_pred))\n",
    "\n",
    "print('--------')\n",
    "\n",
    "print('Train Confusion Matrix:')\n",
    "\n",
    "cm_train_etsc = confusion_matrix(y_train, y_train_etsc_pred, labels = classes)\n",
    "\n",
    "fig = sns.heatmap(cm_train_etsc, annot = True, fmt = 'd', cbar = False)\n",
    "\n",
    "plt.xlabel('Pedicted')\n",
    "\n",
    "plt.ylabel('True')\n",
    "\n",
    "plt.show()\n",
    "    \n",
    "print('--------')\n",
    "\n",
    "print('Test Confusion Matrix:')\n",
    "\n",
    "cm_test_etsc = confusion_matrix(y_test, y_test_etsc_pred, labels = classes)\n",
    "\n",
    "fig = sns.heatmap(cm_test_etsc, annot = True, fmt = 'd', cbar = False)\n",
    "\n",
    "plt.xlabel('Pedicted')\n",
    "\n",
    "plt.ylabel('True')\n",
    "\n",
    "plt.show()\n",
    "    \n",
    "print('--------')\n",
    "\n",
    "print('Test Classification Report:')\n",
    "\n",
    "print(classification_report(y_test,y_test_etsc_pred))\n",
    "\n",
    "report = classification_report(y_test,y_test_etsc_pred, output_dict = True)\n",
    "\n",
    "report1 = pd.DataFrame(report).transpose()\n",
    "\n",
    "report1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DF.append(['etsc', 'gini', 0, \n",
    "           round(etsc.score(X_train, y_train), 5), round(etsc.score(X_test, y_test), 5), \n",
    "           round(matthews_corrcoef(y_train, y_train_etsc_pred), 5), \n",
    "           round(matthews_corrcoef(y_test, y_test_etsc_pred), 5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra trees with gini and pruning\n",
    "\n",
    "etsc = ExtraTreesClassifier(n_estimators = 50, random_state = random_state, ccp_alpha = 0.01)\n",
    "\n",
    "# ExtraTreesClassifier(n_estimators=100, *, criterion='gini', max_depth=None, \n",
    "#                     min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
    "#                     max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
    "#                     bootstrap=False, oob_score=False, n_jobs=None, \n",
    "#                     random_state=None, verbose=0, warm_start=False, class_weight=None, \n",
    "#                     ccp_alpha=0.0, max_samples=None)\n",
    "\n",
    "etsc.fit(X_train, y_train)\n",
    "\n",
    "y_train_etsc_pred = etsc.predict(X_train)\n",
    "\n",
    "y_test_etsc_pred = etsc.predict(X_test)\n",
    "\n",
    "print('Train Score:', etsc.score(X_train, y_train))\n",
    "\n",
    "print('Test Score:', etsc.score(X_test, y_test))\n",
    "\n",
    "print('Train Matthews Corr:', matthews_corrcoef(y_train, y_train_etsc_pred))\n",
    "\n",
    "print('Test Matthews Corr:', matthews_corrcoef(y_test, y_test_etsc_pred))\n",
    "\n",
    "print('--------')\n",
    "\n",
    "print('Train Confusion Matrix:')\n",
    "\n",
    "cm_train_etsc = confusion_matrix(y_train, y_train_etsc_pred, labels = classes)\n",
    "\n",
    "fig = sns.heatmap(cm_train_etsc, annot = True, fmt = 'd', cbar = False)\n",
    "\n",
    "plt.xlabel('Pedicted')\n",
    "\n",
    "plt.ylabel('True')\n",
    "\n",
    "plt.show()\n",
    "    \n",
    "print('--------')\n",
    "\n",
    "print('Test Confusion Matrix:')\n",
    "\n",
    "cm_test_etsc = confusion_matrix(y_test, y_test_etsc_pred, labels = classes)\n",
    "\n",
    "fig = sns.heatmap(cm_test_etsc, annot = True, fmt = 'd', cbar = False)\n",
    "\n",
    "plt.xlabel('Pedicted')\n",
    "\n",
    "plt.ylabel('True')\n",
    "\n",
    "plt.show()\n",
    "    \n",
    "print('--------')\n",
    "\n",
    "print('Test Classification Report:')\n",
    "\n",
    "print(classification_report(y_test,y_test_etsc_pred))\n",
    "\n",
    "report = classification_report(y_test,y_test_etsc_pred, output_dict = True)\n",
    "\n",
    "report1 = pd.DataFrame(report).transpose()\n",
    "\n",
    "report1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DF.append(['etsc', 'gini', 1, \n",
    "           round(etsc.score(X_train, y_train), 5), round(etsc.score(X_test, y_test), 5), \n",
    "           round(matthews_corrcoef(y_train, y_train_etsc_pred), 5), \n",
    "           round(matthews_corrcoef(y_test, y_test_etsc_pred), 5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra Trees  with Entropy Criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra trees with entropy\n",
    "\n",
    "etsc = ExtraTreesClassifier(n_estimators = 50, random_state = random_state, criterion = 'entropy')\n",
    "\n",
    "# ExtraTreesClassifier(n_estimators=100, *, criterion='gini', max_depth=None, \n",
    "#                     min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
    "#                     max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
    "#                     bootstrap=False, oob_score=False, n_jobs=None, \n",
    "#                     random_state=None, verbose=0, warm_start=False, class_weight=None, \n",
    "#                     ccp_alpha=0.0, max_samples=None)\n",
    "\n",
    "etsc.fit(X_train, y_train)\n",
    "\n",
    "y_train_etsc_pred = etsc.predict(X_train)\n",
    "\n",
    "y_test_etsc_pred = etsc.predict(X_test)\n",
    "\n",
    "print('Train Score:', etsc.score(X_train, y_train))\n",
    "\n",
    "print('Test Score:', etsc.score(X_test, y_test))\n",
    "\n",
    "print('Train Matthews Corr:', matthews_corrcoef(y_train, y_train_etsc_pred))\n",
    "\n",
    "print('Test Matthews Corr:', matthews_corrcoef(y_test, y_test_etsc_pred))\n",
    "\n",
    "print('--------')\n",
    "\n",
    "print('Train Confusion Matrix:')\n",
    "\n",
    "cm_train_etsc = confusion_matrix(y_train, y_train_etsc_pred, labels = classes)\n",
    "\n",
    "fig = sns.heatmap(cm_train_etsc, annot = True, fmt = 'd', cbar = False)\n",
    "\n",
    "plt.xlabel('Pedicted')\n",
    "\n",
    "plt.ylabel('True')\n",
    "\n",
    "plt.show()\n",
    "    \n",
    "print('--------')\n",
    "\n",
    "print('Test Confusion Matrix:')\n",
    "\n",
    "cm_test_etsc = confusion_matrix(y_test, y_test_etsc_pred, labels = classes)\n",
    "\n",
    "fig = sns.heatmap(cm_test_etsc, annot = True, fmt = 'd', cbar = False)\n",
    "\n",
    "plt.xlabel('Pedicted')\n",
    "\n",
    "plt.ylabel('True')\n",
    "\n",
    "plt.show()\n",
    "    \n",
    "print('--------')\n",
    "\n",
    "print('Test Classification Report:')\n",
    "\n",
    "print(classification_report(y_test,y_test_etsc_pred))\n",
    "\n",
    "report = classification_report(y_test,y_test_etsc_pred, output_dict = True)\n",
    "\n",
    "report1 = pd.DataFrame(report).transpose()\n",
    "\n",
    "report1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.append(['etsc', 'entropy', 0, \n",
    "           round(etsc.score(X_train, y_train), 5), round(etsc.score(X_test, y_test), 5), \n",
    "           round(matthews_corrcoef(y_train, y_train_etsc_pred), 5), \n",
    "           round(matthews_corrcoef(y_test, y_test_etsc_pred), 5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra trees with entropy and pruning\n",
    "\n",
    "etsc = ExtraTreesClassifier(n_estimators = 50, random_state = random_state, criterion = 'entropy', \n",
    "                           ccp_alpha = 0.02)\n",
    "\n",
    "# ExtraTreesClassifier(n_estimators=100, *, criterion='gini', max_depth=None, \n",
    "#                     min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
    "#                     max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
    "#                     bootstrap=False, oob_score=False, n_jobs=None, \n",
    "#                     random_state=None, verbose=0, warm_start=False, class_weight=None, \n",
    "#                     ccp_alpha=0.0, max_samples=None)\n",
    "\n",
    "etsc.fit(X_train, y_train)\n",
    "\n",
    "y_train_etsc_pred = etsc.predict(X_train)\n",
    "\n",
    "y_test_etsc_pred = etsc.predict(X_test)\n",
    "\n",
    "print('Train Score:', etsc.score(X_train, y_train))\n",
    "\n",
    "print('Test Score:', etsc.score(X_test, y_test))\n",
    "\n",
    "print('Train Matthews Corr:', matthews_corrcoef(y_train, y_train_etsc_pred))\n",
    "\n",
    "print('Test Matthews Corr:', matthews_corrcoef(y_test, y_test_etsc_pred))\n",
    "\n",
    "print('--------')\n",
    "\n",
    "print('Train Confusion Matrix:')\n",
    "\n",
    "cm_train_etsc = confusion_matrix(y_train, y_train_etsc_pred, labels = classes)\n",
    "\n",
    "fig = sns.heatmap(cm_train_etsc, annot = True, fmt = 'd', cbar = False)\n",
    "\n",
    "plt.xlabel('Pedicted')\n",
    "\n",
    "plt.ylabel('True')\n",
    "\n",
    "plt.show()\n",
    "    \n",
    "print('--------')\n",
    "\n",
    "print('Test Confusion Matrix:')\n",
    "\n",
    "cm_test_etsc = confusion_matrix(y_test, y_test_etsc_pred, labels = classes)\n",
    "\n",
    "fig = sns.heatmap(cm_test_etsc, annot = True, fmt = 'd', cbar = False)\n",
    "\n",
    "plt.xlabel('Pedicted')\n",
    "\n",
    "plt.ylabel('True')\n",
    "\n",
    "plt.show()\n",
    "    \n",
    "print('--------')\n",
    "\n",
    "print('Test Classification Report:')\n",
    "\n",
    "print(classification_report(y_test,y_test_etsc_pred))\n",
    "\n",
    "report = classification_report(y_test,y_test_etsc_pred, output_dict = True)\n",
    "\n",
    "report1 = pd.DataFrame(report).transpose()\n",
    "\n",
    "report1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.append(['etsc', 'entropy', 1, \n",
    "           round(etsc.score(X_train, y_train), 5), round(etsc.score(X_test, y_test), 5), \n",
    "           round(matthews_corrcoef(y_train, y_train_etsc_pred), 5), \n",
    "           round(matthews_corrcoef(y_test, y_test_etsc_pred), 5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear SVC\n",
    "\n",
    "svc = SVC(kernel = 'linear', random_state = random_state)\n",
    "\n",
    "# SVC(*, C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, \n",
    "#    probability=False, tol=0.001, cache_size=200, class_weight=None, \n",
    "#    verbose=False, max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=None)\n",
    "\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "y_train_svc_pred = svc.predict(X_train)\n",
    "\n",
    "y_test_svc_pred = svc.predict(X_test)\n",
    "\n",
    "print('Train Score:', svc.score(X_train, y_train))\n",
    "\n",
    "print('Test Score:', svc.score(X_test, y_test))\n",
    "\n",
    "print('Train Matthews Corr:', matthews_corrcoef(y_train, y_train_svc_pred))\n",
    "\n",
    "print('Test Matthews Corr:', matthews_corrcoef(y_test, y_test_svc_pred))\n",
    "\n",
    "print('--------')\n",
    "\n",
    "print('Train Confusion Matrix:')\n",
    "\n",
    "cm_train_svc = confusion_matrix(y_train, y_train_svc_pred, labels = classes)\n",
    "\n",
    "fig = sns.heatmap(cm_train_svc, annot = True, fmt = 'd', cbar = False)\n",
    "\n",
    "plt.xlabel('Pedicted')\n",
    "\n",
    "plt.ylabel('True')\n",
    "\n",
    "plt.show()\n",
    "    \n",
    "print('--------')\n",
    "\n",
    "print('Test Confusion Matrix:')\n",
    "\n",
    "cm_test_svc = confusion_matrix(y_test, y_test_svc_pred, labels = classes)\n",
    "\n",
    "fig = sns.heatmap(cm_test_svc, annot = True, fmt = 'd', cbar = False)\n",
    "\n",
    "plt.xlabel('Pedicted')\n",
    "\n",
    "plt.ylabel('True')\n",
    "\n",
    "plt.show()\n",
    "    \n",
    "print('--------')\n",
    "\n",
    "print('Test Classification Report:')\n",
    "\n",
    "print(classification_report(y_test, y_test_svc_pred))\n",
    "\n",
    "report = classification_report(y_test, y_test_svc_pred, output_dict = True)\n",
    "\n",
    "report1 = pd.DataFrame(report).transpose()\n",
    "\n",
    "report1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.append(['svc', 'na', 'na', \n",
    "           round(svc.score(X_train, y_train), 5), round(svc.score(X_test, y_test), 5), \n",
    "           round(matthews_corrcoef(y_train, y_train_svc_pred), 5), \n",
    "           round(matthews_corrcoef(y_test, y_test_svc_pred), 5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quadratic SVC\n",
    "\n",
    "svc2 = SVC(kernel = 'poly', degree = 2, random_state = random_state, gamma = 'auto')\n",
    "\n",
    "# SVC(*, C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, \n",
    "#    probability=False, tol=0.001, cache_size=200, class_weight=None, \n",
    "#    verbose=False, max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=None)\n",
    "\n",
    "svc2.fit(X_train, y_train)\n",
    "\n",
    "y_train_svc2_pred = svc2.predict(X_train)\n",
    "\n",
    "y_test_svc2_pred = svc2.predict(X_test)\n",
    "\n",
    "print('Train Score:', svc2.score(X_train, y_train))\n",
    "\n",
    "print('Test Score:', svc2.score(X_test, y_test))\n",
    "\n",
    "print('Train Matthews Corr:', matthews_corrcoef(y_train, y_train_svc2_pred))\n",
    "\n",
    "print('Test Matthews Corr:', matthews_corrcoef(y_test, y_test_svc2_pred))\n",
    "\n",
    "print('--------')\n",
    "\n",
    "print('Train Confusion Matrix:')\n",
    "\n",
    "cm_train_svc2 = confusion_matrix(y_train, y_train_svc2_pred, labels = classes)\n",
    "\n",
    "fig = sns.heatmap(cm_train_svc2, annot = True, fmt = 'd', cbar = False)\n",
    "\n",
    "plt.xlabel('Pedicted')\n",
    "\n",
    "plt.ylabel('True')\n",
    "\n",
    "plt.show()\n",
    "    \n",
    "print('--------')\n",
    "\n",
    "print('Test Confusion Matrix:')\n",
    "\n",
    "cm_test_svc2 = confusion_matrix(y_test, y_test_svc2_pred, labels = classes)\n",
    "\n",
    "fig = sns.heatmap(cm_test_svc2, annot = True, fmt = 'd', cbar = False)\n",
    "\n",
    "plt.xlabel('Pedicted')\n",
    "\n",
    "plt.ylabel('True')\n",
    "\n",
    "plt.show()\n",
    "    \n",
    "print('--------')\n",
    "\n",
    "print('Test Classification Report:')\n",
    "\n",
    "print(classification_report(y_test, y_test_svc2_pred))\n",
    "\n",
    "report = classification_report(y_test, y_test_svc2_pred, output_dict = True)\n",
    "\n",
    "report1 = pd.DataFrame(report).transpose()\n",
    "\n",
    "report1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DF.append(['svc2', 'na', 'na', \n",
    "           round(svc2.score(X_train, y_train), 5), round(svc2.score(X_test, y_test), 5), \n",
    "           round(matthews_corrcoef(y_train, y_train_svc2_pred), 5), \n",
    "           round(matthews_corrcoef(y_test, y_test_svc2_pred), 5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF2 = pd.DataFrame(np.array(DF), columns = ['Method', 'Criterion', 'Pruning', 'TrainScore',\n",
    "                                            'TestScore', 'TrainCorr', 'TestCorr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
