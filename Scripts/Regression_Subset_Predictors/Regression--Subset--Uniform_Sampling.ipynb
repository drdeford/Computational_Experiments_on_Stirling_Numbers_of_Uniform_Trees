{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries \n",
    "# make sure that tree_functions_2.py is in the same directory as this notebook\n",
    "\n",
    "from tree_functions_2 import *\n",
    "\n",
    "# calling the appropriate tools for regression\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor, Ridge, Lasso, ElasticNet\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, explained_variance_score\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change figure configurations\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "font = {'size':16}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "matplotlib.rc('figure', figsize = (5.0, 5.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the order of the trees \n",
    "\n",
    "n = 18\n",
    "\n",
    "l = int(np.ceil(n / 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting a random seed\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the Tree List and the Associated Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling 500 trees using unifrom sampling\n",
    "\n",
    "K_n = nx.complete_graph(n)\n",
    "\n",
    "Tree_List = []\n",
    "\n",
    "for i in range(500):\n",
    "    \n",
    "    Tree_List.append(nx.to_networkx_graph(get_spanning_tree_u_w(K_n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes for trees (0 is path-like and 1 is star-like)\n",
    "\n",
    "classes = [0, 1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation-based total ordering on Tree_List\n",
    "\n",
    "total_tree_evaluation_list = get_total_list_evaluation_based(Tree_List, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifying the trees Tree_List as 'path-like' and 'star-like'\n",
    "# based on the total ordering\n",
    "\n",
    "for j in range(len(total_tree_evaluation_list)):\n",
    "    \n",
    "    if j < len(total_tree_evaluation_list)/2:\n",
    "        \n",
    "        total_tree_evaluation_list[j].append(classes[0])\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        total_tree_evaluation_list[j].append(classes[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data frame containing the following graph statistics:\n",
    "# log_{10}(P(.;2,1)), radius,  diameter, degree centrality, \n",
    "# closeness centrality, between centrality,\n",
    "# Stirling Numbers of the First Kind for Trees, number of leaves, and class \n",
    "\n",
    "df = []\n",
    "\n",
    "for i in range(len(total_tree_evaluation_list)):\n",
    "    \n",
    "    x = total_tree_evaluation_list[i]\n",
    "        \n",
    "    df.append([np.log10(float(x[0])), nx.radius(x[1]), nx.diameter(x[1]),\n",
    "               get_degree_centrality(x[1]),\n",
    "               get_closeness_centrality(x[1]),\n",
    "               get_betweenness_centrality(x[1]),\n",
    "               get_stirling_trees(x[1], n),\n",
    "               get_leaf_number(x[1]),\n",
    "              x[3]])\n",
    "    \n",
    "df = pd.DataFrame(df, columns = ['Log_Dist', 'Rad', 'Diam', 'Deg_Cent', \n",
    "                                 'Cls_Cent', 'Btw_Cent', 'Stirling', 'Leaf_Num', 'Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Splitting the Tree List to Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, [4, 5, 8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame(np.array(list(df.loc[:, 'Stirling']))).iloc[:, 0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.5, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing Regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting a random seed\n",
    "\n",
    "random_state =  np.random.RandomState(seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_trunc = np.ravel(np.array(list(y_train.iloc[:, k])))\n",
    "\n",
    "y_test_trunc = np.ravel(np.array(list(y_test.iloc[:, k])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "\n",
    "reg = LinearRegression()\n",
    "\n",
    "# LinearRegression(,fit_intercept=True, normalize='deprecated', copy_X=True, n_jobs=None, positive=False)\n",
    "\n",
    "reg.fit(X_train, y_train_trunc)\n",
    "\n",
    "y_pred_train = reg.predict(X_train)\n",
    "\n",
    "y_pred_test = reg.predict(X_test)\n",
    "\n",
    "print('Train MSE:', mean_squared_error(y_train_trunc, y_pred_train))\n",
    "\n",
    "print('Test MSE:', mean_squared_error(y_test_trunc, y_pred_test))\n",
    "\n",
    "print('--------')\n",
    "\n",
    "print('Train Score:', reg.score(X_train, y_train_trunc))\n",
    "\n",
    "print('Test Score:', reg.score(X_test, y_test_trunc))\n",
    "\n",
    "print('--------')\n",
    "\n",
    "print('Train EVS:', explained_variance_score(y_train_trunc, y_pred_train))\n",
    "\n",
    "print('Test EVS:', explained_variance_score(y_test_trunc, y_pred_test))\n",
    "\n",
    "print('--------')\n",
    "\n",
    "print('Reg. Coef.:', reg.coef_)\n",
    "\n",
    "print('Reg. Intercept:', reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_reg(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    for m in range(shape(y_train)[1] - 1):\n",
    "    \n",
    "        y_train_trunc = np.ravel(np.array(list(y_train.iloc[:, m])))\n",
    "\n",
    "        y_test_trunc = np.ravel(np.array(list(y_test.iloc[:, m])))\n",
    "    \n",
    "        reg = LinearRegression()\n",
    "        \n",
    "        reg.fit(X_train, y_train_trunc)\n",
    "\n",
    "        y_pred_train = reg.predict(X_train)\n",
    "\n",
    "        y_pred_train_rounded = [np.rint(y_pred_train[i]) for i in range(len(y_pred_train))]\n",
    "\n",
    "        y_pred_test = reg.predict(X_test)\n",
    "\n",
    "        y_pred_test_rounded = [np.rint(y_pred_test[i]) for i in range(len(y_pred_test))]\n",
    "\n",
    "        DF.append(['linear', m + l,\n",
    "                   round(reg.score(X_train, y_train_trunc), 5),\n",
    "                   round(reg.score(X_test, y_test_trunc), 5),\n",
    "                   round(explained_variance_score(y_train_trunc, y_pred_train), 5),\n",
    "                   round(explained_variance_score(y_test_trunc, y_pred_test), 5)])\n",
    "        \n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_reg(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge Regression\n",
    "\n",
    "rng = Ridge(random_state = random_state)\n",
    "\n",
    "# Ridge(alpha=1.0, *, fit_intercept=True, normalize='deprecated', \n",
    "#       copy_X=True, max_iter=None, tol=0.001, solver='auto', \n",
    "#       positive=False, random_state=None)\n",
    "\n",
    "rng.fit(X_train, y_train_trunc)\n",
    "\n",
    "y_pred_train = rng.predict(X_train)\n",
    "\n",
    "y_pred_test = rng.predict(X_test)\n",
    "\n",
    "print('Train MSE:', mean_squared_error(y_train_trunc, y_pred_train))\n",
    "\n",
    "print('Test MSE:', mean_squared_error(y_test_trunc, y_pred_test))\n",
    "\n",
    "print('--------')\n",
    "\n",
    "print('Train Score:', rng.score(X_train, y_train_trunc))\n",
    "\n",
    "print('Test Score:', rng.score(X_test, y_test_trunc))\n",
    "\n",
    "print('--------')\n",
    "\n",
    "print('Train EVS:', explained_variance_score(y_train_trunc, y_pred_train))\n",
    "\n",
    "print('Test EVS:', explained_variance_score(y_test_trunc, y_pred_test))\n",
    "\n",
    "print('--------')\n",
    "\n",
    "print('Reg. Coef.:', rng.coef_)\n",
    "\n",
    "print('Reg. Intercept:', rng.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    for m in range(shape(y_train)[1] - 1): \n",
    "    \n",
    "        y_train_trunc = np.ravel(np.array(list(y_train.iloc[:, m])))\n",
    "\n",
    "        y_test_trunc = np.ravel(np.array(list(y_test.iloc[:, m])))\n",
    "        \n",
    "        rng = Ridge(random_state = random_state)\n",
    "\n",
    "        rng.fit(X_train, y_train_trunc)\n",
    "\n",
    "        y_pred_train = rng.predict(X_train)\n",
    "\n",
    "        y_pred_train_rounded = [np.rint(y_pred_train[i]) for i in range(len(y_pred_train))]\n",
    "\n",
    "        y_pred_test = rng.predict(X_test)\n",
    "\n",
    "        y_pred_test_rounded = [np.rint(y_pred_test[i]) for i in range(len(y_pred_test))]\n",
    "\n",
    "        DF.append(['ridge', m + l,\n",
    "                   round(rng.score(X_train, y_train_trunc), 5),\n",
    "                   round(rng.score(X_test, y_test_trunc), 5),\n",
    "                   round(explained_variance_score(y_train_trunc, y_pred_train), 5),\n",
    "                   round(explained_variance_score(y_test_trunc, y_pred_test), 5)])\n",
    "    \n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso Regression\n",
    "\n",
    "lss = Lasso(random_state = random_state)\n",
    "\n",
    "# Lasso(alpha=1.0, *, fit_intercept=True, normalize='deprecated', \n",
    "#       precompute=False, copy_X=True, max_iter=1000, tol=0.0001, \n",
    "#       warm_start=False, positive=False, \n",
    "#       random_state=None, selection='cyclic')\n",
    "\n",
    "lss.fit(X_train, y_train_trunc)\n",
    "\n",
    "y_pred_train = lss.predict(X_train)\n",
    "\n",
    "y_pred_test = lss.predict(X_test)\n",
    "\n",
    "print('Train MSE:', mean_squared_error(y_train_trunc, y_pred_train))\n",
    "\n",
    "print('Test MSE:', mean_squared_error(y_test_trunc, y_pred_test))\n",
    "\n",
    "print('--------')\n",
    "\n",
    "print('Train Score:', lss.score(X_train, y_train_trunc))\n",
    "\n",
    "print('Test Score:', lss.score(X_test, y_test_trunc))\n",
    "\n",
    "print('--------')\n",
    "\n",
    "print('Train EVS:', explained_variance_score(y_train_trunc, y_pred_train))\n",
    "\n",
    "print('Test EVS:', explained_variance_score(y_test_trunc, y_pred_test))\n",
    "\n",
    "print('--------')\n",
    "\n",
    "print('Reg. Coef.:', lss.coef_)\n",
    "\n",
    "print('Reg. Intercept:', lss.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    for m in range(shape(y_train)[1] - 1): \n",
    "        \n",
    "        y_train_trunc = np.ravel(np.array(list(y_train.iloc[:, m])))\n",
    "\n",
    "        y_test_trunc = np.ravel(np.array(list(y_test.iloc[:, m])))\n",
    "        \n",
    "        lss = Lasso(random_state = random_state)\n",
    "\n",
    "        lss.fit(X_train, y_train_trunc)\n",
    "\n",
    "        y_pred_train = lss.predict(X_train)\n",
    "\n",
    "        y_pred_train_rounded = [np.rint(y_pred_train[i]) for i in range(len(y_pred_train))]\n",
    "\n",
    "        y_pred_test = lss.predict(X_test)\n",
    "\n",
    "        y_pred_test_rounded = [np.rint(y_pred_test[i]) for i in range(len(y_pred_test))]\n",
    "\n",
    "        DF.append(['lasso', m + l,\n",
    "                   round(lss.score(X_train, y_train_trunc), 5),\n",
    "                   round(lss.score(X_test, y_test_trunc), 5),\n",
    "                   round(explained_variance_score(y_train_trunc, y_pred_train), 5),\n",
    "                   round(explained_variance_score(y_test_trunc, y_pred_test), 5)])\n",
    "        \n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elastic Net\n",
    "\n",
    "ent = ElasticNet(random_state = random_state)\n",
    "\n",
    "# ElasticNet(alpha=1.0, *, l1_ratio=0.5, fit_intercept=True, \n",
    "#            normalize='deprecated', precompute=False, max_iter=1000, \n",
    "#            copy_X=True, tol=0.0001, warm_start=False, \n",
    "#            positive=False, random_state=None, selection='cyclic')\n",
    "\n",
    "ent.fit(X_train, y_train_trunc)\n",
    "\n",
    "y_pred_train = ent.predict(X_train)\n",
    "\n",
    "y_pred_test = ent.predict(X_test)\n",
    "\n",
    "print('Train MSE:', mean_squared_error(y_train_trunc, y_pred_train))\n",
    "\n",
    "print('Test MSE:', mean_squared_error(y_test_trunc, y_pred_test))\n",
    "\n",
    "print('--------')\n",
    "\n",
    "print('Train Score:', ent.score(X_train, y_train_trunc))\n",
    "\n",
    "print('Test Score:', ent.score(X_test, y_test_trunc))\n",
    "\n",
    "print('--------')\n",
    "\n",
    "print('Train EVS:', explained_variance_score(y_train_trunc, y_pred_train))\n",
    "\n",
    "print('Test EVS:', explained_variance_score(y_test_trunc, y_pred_test))\n",
    "\n",
    "print('--------')\n",
    "\n",
    "print('Reg. Coef.:', ent.coef_)\n",
    "\n",
    "print('Reg. Intercept:', ent.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    for m in range(shape(y_train)[1] - 1): \n",
    "        \n",
    "        y_train_trunc = np.ravel(np.array(list(y_train.iloc[:, m])))\n",
    "\n",
    "        y_test_trunc = np.ravel(np.array(list(y_test.iloc[:, m])))\n",
    "        \n",
    "        ent = ElasticNet(random_state = random_state)\n",
    "\n",
    "        ent.fit(X_train, y_train_trunc)\n",
    "\n",
    "        y_pred_train = ent.predict(X_train)\n",
    "\n",
    "        y_pred_train_rounded = [np.rint(y_pred_train[i]) for i in range(len(y_pred_train))]\n",
    "\n",
    "        y_pred_test = ent.predict(X_test)\n",
    "\n",
    "        y_pred_test_rounded = [np.rint(y_pred_test[i]) for i in range(len(y_pred_test))]\n",
    "\n",
    "        DF.append(['elasticnet',  m + l,\n",
    "                   round(ent.score(X_train, y_train_trunc), 5),\n",
    "                   round(ent.score(X_test, y_test_trunc), 5),\n",
    "                   round(explained_variance_score(y_train_trunc, y_pred_train), 5),\n",
    "                   round(explained_variance_score(y_test_trunc, y_pred_test), 5)])\n",
    "        \n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quadratic Regression \n",
    "\n",
    "model = Pipeline([('poly', PolynomialFeatures(degree = 2)), ('reg', LinearRegression())])\n",
    "\n",
    "# PolynomialFeatures(degree=2, *, interaction_only=False, include_bias=True, order='C')\n",
    "\n",
    "model.fit(X_train, y_train_trunc)\n",
    "\n",
    "y_poly_train_pred = model.predict(X_train)\n",
    "\n",
    "y_poly_test_pred = model.predict(X_test)\n",
    "\n",
    "print('Train MSE:', mean_squared_error(y_train_trunc, y_poly_train_pred))\n",
    "\n",
    "print('Test MSE:', mean_squared_error(y_test_trunc, y_poly_test_pred))\n",
    "\n",
    "print('--------')\n",
    "\n",
    "print('Train Score:', model.score(X_train, y_train_trunc))\n",
    "\n",
    "print('Test Score:', model.score(X_test, y_test_trunc))\n",
    "\n",
    "print('--------')\n",
    "\n",
    "print('Train EVS:', explained_variance_score(y_train_trunc, y_poly_train_pred))\n",
    "\n",
    "print('Test EVS:', explained_variance_score(y_test_trunc, y_poly_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def poly_2(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    for m in range(shape(y_train)[1] - 1): \n",
    "        \n",
    "        y_train_trunc = np.ravel(np.array(list(y_train.iloc[:, m])))\n",
    "\n",
    "        y_test_trunc = np.ravel(np.array(list(y_test.iloc[:, m])))\n",
    "        \n",
    "        model = Pipeline([('poly', PolynomialFeatures(degree = 2)), ('reg', LinearRegression())])\n",
    "        \n",
    "        model.fit(X_train, y_train_trunc)\n",
    "\n",
    "        y_poly_train_pred = model.predict(X_train)\n",
    "\n",
    "        y_poly_train_pred_rounded = [np.rint(y_poly_train_pred[i]) for i in range(len(y_poly_train_pred))]\n",
    "\n",
    "        y_poly_test_pred = model.predict(X_test)\n",
    "\n",
    "        y_poly_test_pred_rounded = [np.rint(y_poly_test_pred[i]) for i in range(len(y_poly_test_pred))]\n",
    "\n",
    "        DF.append(['quadratic',  m + l,\n",
    "               round(model.score(X_train, y_train_trunc), 5),\n",
    "               round(model.score(X_test, y_test_trunc), 5),\n",
    "               round(explained_variance_score(y_train_trunc, y_pred_train), 5),\n",
    "               round(explained_variance_score(y_test_trunc, y_pred_test), 5)])\n",
    "                  \n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_2(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stochatic Gradient Descent\n",
    "\n",
    "sgd = make_pipeline(StandardScaler(), SGDRegressor(random_state = random_state))\n",
    "\n",
    "# SGDRegressor(loss='squared_error', *, penalty='l2', alpha=0.0001, \n",
    "#              l1_ratio=0.15, fit_intercept=True, max_iter=1000, \n",
    "#              tol=0.001, shuffle=True, verbose=0, epsilon=0.1, \n",
    "#              random_state=None, learning_rate='invscaling', eta0=0.01, \n",
    "#              power_t=0.25, early_stopping=False, validation_fraction=0.1, \n",
    "#              n_iter_no_change=5, warm_start=False, average=False)\n",
    "\n",
    "sgd.fit(X_train, y_train_trunc)\n",
    "\n",
    "y_sgd_train_pred = sgd.predict(X_train)\n",
    "\n",
    "y_sgd_test_pred = sgd.predict(X_test)\n",
    "\n",
    "print('Train MSE:', mean_squared_error(y_train_trunc, y_sgd_train_pred))\n",
    "\n",
    "print('Test MSE:', mean_squared_error(y_test_trunc, y_sgd_test_pred))\n",
    "\n",
    "print('--------')\n",
    "\n",
    "print('Train Score:', sgd.score(X_train, y_train_trunc))\n",
    "\n",
    "print('Test Score:', sgd.score(X_test, y_test_trunc))\n",
    "\n",
    "print('--------')\n",
    "\n",
    "print('Train EVS:', explained_variance_score(y_train_trunc, y_sgd_train_pred))\n",
    "\n",
    "print('Test EVS:', explained_variance_score(y_test_trunc, y_sgd_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    for m in range(shape(y_train)[1] - 1):          \n",
    "                \n",
    "        y_train_trunc = np.ravel(np.array(list(y_train.iloc[:, m])))\n",
    "\n",
    "        y_test_trunc = np.ravel(np.array(list(y_test.iloc[:, m]))) \n",
    "    \n",
    "        sgd = make_pipeline(StandardScaler(), SGDRegressor(random_state = random_state))\n",
    "\n",
    "        sgd.fit(X_train, y_train_trunc)\n",
    "\n",
    "        y_sgd_train_pred = sgd.predict(X_train)\n",
    "\n",
    "        y_sgd_train_pred_rounded = [np.rint(y_sgd_train_pred[i]) for i in range(len(y_sgd_train_pred))]\n",
    "\n",
    "        y_sgd_test_pred = sgd.predict(X_test)\n",
    "\n",
    "        y_sgd_test_pred_rounded = [np.rint(y_sgd_test_pred[i]) for i in range(len(y_sgd_test_pred))]\n",
    "    \n",
    "        DF.append(['sgd',  m + l,\n",
    "                   round(ent.score(X_train, y_train_trunc), 5),\n",
    "                   round(ent.score(X_test, y_test_trunc), 5),\n",
    "                   round(explained_variance_score(y_train_trunc, y_pred_train), 5),\n",
    "                   round(explained_variance_score(y_test_trunc, y_pred_test), 5)])\n",
    "        \n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stochastic(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear svr\n",
    "\n",
    "# SVR(*, kernel='rbf', degree=3, gamma='scale', coef0=0.0, \n",
    "#    tol=0.001, C=1.0, epsilon=0.1, shrinking=True, \n",
    "#    cache_size=200, verbose=False, max_iter=-1)\n",
    "\n",
    "def sv_reg(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    for m in range(shape(y_train)[1] - 1):\n",
    "    \n",
    "        y_train_trunc = np.ravel(np.array(list(y_train.iloc[:, m])))\n",
    "\n",
    "        y_test_trunc = np.ravel(np.array(list(y_test.iloc[:, m])))\n",
    "    \n",
    "        svr = SVR(kernel = 'linear')\n",
    "        \n",
    "        svr.fit(X_train, y_train_trunc)\n",
    "\n",
    "        y_pred_train = svr.predict(X_train)\n",
    "\n",
    "        y_pred_train_rounded = [np.rint(y_pred_train[i]) for i in range(len(y_pred_train))]\n",
    "\n",
    "        y_pred_test = svr.predict(X_test)\n",
    "\n",
    "        y_pred_test_rounded = [np.rint(y_pred_test[i]) for i in range(len(y_pred_test))]\n",
    "\n",
    "        DF.append(['svr', m + l,\n",
    "                   round(svr.score(X_train, y_train_trunc), 5),\n",
    "                   round(svr.score(X_test, y_test_trunc), 5),\n",
    "                   round(explained_variance_score(y_train_trunc, y_pred_train), 5),\n",
    "                   round(explained_variance_score(y_test_trunc, y_pred_test), 5)])\n",
    "        \n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_reg(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quadratic svr\n",
    "\n",
    "# SVR(*, kernel='rbf', degree=3, gamma='scale', coef0=0.0, \n",
    "#    tol=0.001, C=1.0, epsilon=0.1, shrinking=True, \n",
    "#    cache_size=200, verbose=False, max_iter=-1)\n",
    "\n",
    "def sv2_reg(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    for m in range(shape(y_train)[1] - 1):\n",
    "    \n",
    "        y_train_trunc = np.ravel(np.array(list(y_train.iloc[:, m])))\n",
    "\n",
    "        y_test_trunc = np.ravel(np.array(list(y_test.iloc[:, m])))\n",
    "    \n",
    "        svr2 = SVR(kernel = 'poly', degree = 2, gamma = 'auto')\n",
    "        \n",
    "        svr2.fit(X_train, y_train_trunc)\n",
    "\n",
    "        y_pred_train = svr2.predict(X_train)\n",
    "\n",
    "        y_pred_train_rounded = [np.rint(y_pred_train[i]) for i in range(len(y_pred_train))]\n",
    "\n",
    "        y_pred_test = svr2.predict(X_test)\n",
    "\n",
    "        y_pred_test_rounded = [np.rint(y_pred_test[i]) for i in range(len(y_pred_test))]\n",
    "\n",
    "        DF.append(['svr2', m + l,\n",
    "                   round(svr2.score(X_train, y_train_trunc), 5),\n",
    "                   round(svr2.score(X_test, y_test_trunc), 5),\n",
    "                   round(explained_variance_score(y_train_trunc, y_pred_train), 5),\n",
    "                   round(explained_variance_score(y_test_trunc, y_pred_test), 5)])\n",
    "        \n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv2_reg(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF2 = pd.DataFrame(np.array(DF), columns = ['Method', 'k',\n",
    "                                            'Train_Score', 'Test_Score',\n",
    "                                            'Train_EVS', 'Test_EVS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF2.to_csv('Regression--Subset--Uniform_Sampling.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
